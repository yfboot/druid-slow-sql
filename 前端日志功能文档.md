# 前端日志功能文档

## 📋 功能概述

前端日志功能支持通过REST API接口收集前端日志并存储到文件系统，提供完整的日志管理和查询功能。

### 核心功能
- **多种日志记录方式** - 单条、批量、快速记录
- **日志文件管理** - 自动滚动、压缩归档、大小控制
- **内容验证** - 防止恶意或异常大小的请求
- **大容量支持** - 单次请求最大20MB，支持大量日志数据
- **异步处理** - 后台异步写入，不影响响应性能

## 📂 日志文件结构

```
logs/
├── frontend/                                    # 前端日志目录
│   ├── druid-slow-sql-frontend.log             # 当前日志文件（25MB）
│   └── archive/                                 # 归档目录
│       ├── druid-slow-sql-frontend-2024-01-20-1.log.gz
│       └── druid-slow-sql-frontend-2024-01-19-1.log.gz
```

### 文件管理策略
- **单文件大小**: 25MB（达到后自动滚动）
- **保留天数**: 30天
- **压缩方式**: gzip压缩归档
- **启动行为**: 系统启动时清空当前日志文件
- **命名规范**: `druid-slow-sql-frontend-{日期}-{序号}.log.gz`

## 🌐 API接口

### 基础URL: `/api/frontend-log`

| 接口 | 方法 | 功能说明 | 参数说明 |
|------|------|----------|----------|
| `/single` | POST | 记录单条日志 | JSON对象，包含完整日志信息 |
| `/batch` | POST | 批量记录日志 | JSON数组，最多100条日志 |
| `/quick` | POST | 快速记录日志 | URL参数方式，适合简单场景 |
| `/config` | GET | 获取配置信息 | 返回支持的日志级别、限制等 |
| `/info` | GET | 获取日志文件信息 | 文件大小、修改时间、日志条数 |
| `/recent` | GET | 获取最近日志内容 | `?lines=50` 返回最近N行 |
| `/init` | POST | 初始化日志目录 | 创建必要的目录结构 |

## 📝 使用示例

### 1. 单条日志记录

```javascript
// 日期格式化函数
function formatDateTime(date) {
    const year = date.getFullYear();
    const month = String(date.getMonth() + 1).padStart(2, '0');
    const day = String(date.getDate()).padStart(2, '0');
    const hours = String(date.getHours()).padStart(2, '0');
    const minutes = String(date.getMinutes()).padStart(2, '0');
    const seconds = String(date.getSeconds()).padStart(2, '0');
    return `${year}-${month}-${day} ${hours}:${minutes}:${seconds}`;
}

// 单条日志记录
const logData = {
    level: "ERROR",                              // 日志级别
    message: "JavaScript运行时错误",             // 日志消息
    module: "UserModule",                        // 模块名称
    userId: "user123",                           // 用户ID
    url: window.location.href,                   // 页面URL
    userAgent: navigator.userAgent,              // 浏览器信息
    metadata: JSON.stringify({                   // 元数据
        sessionId: "abc123",
        ip: "192.168.1.100"
    }),
    stack: error.stack,                          // 错误堆栈
    timestamp: formatDateTime(new Date())        // 时间戳
};

fetch('/api/frontend-log/single', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(logData)
})
.then(response => response.json())
.then(result => console.log('日志记录成功:', result));
```

### 2. 批量日志记录

```javascript
const batchLogs = [
    {
        level: "INFO",
        message: "页面加载完成",
        module: "PageModule",
        userId: "user123",
        timestamp: formatDateTime(new Date())
    },
    {
        level: "WARN",
        message: "网络请求缓慢",
        module: "NetworkModule", 
        userId: "user123",
        timestamp: formatDateTime(new Date())
    }
];

fetch('/api/frontend-log/batch', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify(batchLogs)
})
.then(response => response.json())
.then(result => console.log('批量日志记录成功:', result));
```

### 3. 快速日志记录

```javascript
// 适合简单场景的快速记录
fetch('/api/frontend-log/quick?level=ERROR&message=' + 
      encodeURIComponent('请求失败') + 
      '&module=ApiModule&userId=user123', {
    method: 'POST'
})
.then(response => response.json())
.then(result => console.log('快速日志记录成功:', result));
```

## 📏 内容限制和容量

### 单个字段限制
| 字段 | 最大大小 | 说明 |
|------|----------|------|
| 消息内容 | 10KB | 日志消息主体 |
| 错误堆栈 | 50KB | JavaScript错误堆栈 |
| 元数据 | 5KB | JSON格式的额外数据 |
| URL地址 | 2KB | 页面URL |

### 批量请求限制
- **最大条数**: 100条日志/次
- **请求体大小**: 20MB/次
- **并发连接**: 支持多个并发请求

### 容量计算示例
```
简单日志（约300字节/条）: 单次可提交 ~66,000条
包含堆栈的错误日志（约50KB/条）: 单次可提交 ~400条
混合类型日志: 单次可提交 ~1,000-5,000条
```

## 🔄 高级用法

### 1. 分批提交处理

```javascript
// 处理大量日志的分批提交
function submitLogsInBatches(logs, batchSize = 50) {
    const batches = [];
    for (let i = 0; i < logs.length; i += batchSize) {
        batches.push(logs.slice(i, i + batchSize));
    }
    
    return Promise.all(
        batches.map(batch => 
            fetch('/api/frontend-log/batch', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(batch)
            })
        )
    );
}

// 使用示例
submitLogsInBatches(largeLogArray, 50);
```

### 2. 异步队列管理

```javascript
// 前端日志队列管理
class LogQueue {
    constructor() {
        this.queue = [];
        this.isProcessing = false;
        this.maxQueueSize = 1000;
    }
    
    add(log) {
        if (this.queue.length >= this.maxQueueSize) {
            this.queue.shift(); // 移除最旧日志
        }
        this.queue.push(log);
        this.processQueue();
    }
    
    async processQueue() {
        if (this.isProcessing || this.queue.length === 0) return;
        
        this.isProcessing = true;
        const batch = this.queue.splice(0, 50);
        
        try {
            await fetch('/api/frontend-log/batch', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(batch)
            });
        } catch (error) {
            console.warn('日志提交失败:', error);
        }
        
        this.isProcessing = false;
        
        if (this.queue.length > 0) {
            setTimeout(() => this.processQueue(), 1000);
        }
    }
}

// 全局日志队列使用
const globalLogQueue = new LogQueue();
globalLogQueue.add({ level: 'INFO', message: '用户操作' });
```

### 3. 错误处理和重试

```javascript
// 带超时和重试的日志提交
async function submitWithRetry(logs, maxRetries = 3, timeout = 10000) {
    for (let attempt = 1; attempt <= maxRetries; attempt++) {
        try {
            const controller = new AbortController();
            const timeoutId = setTimeout(() => controller.abort(), timeout);
            
            const response = await fetch('/api/frontend-log/batch', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(logs),
                signal: controller.signal
            });
            
            clearTimeout(timeoutId);
            return response;
            
        } catch (error) {
            console.warn(`日志提交失败 (尝试 ${attempt}/${maxRetries}):`, error);
            
            if (attempt === maxRetries) {
                // 最后一次失败，缓存到本地
                localStorage.setItem('pendingLogs', 
                    JSON.stringify(logs));
            } else {
                // 等待后重试
                await new Promise(resolve => 
                    setTimeout(resolve, 1000 * attempt));
            }
        }
    }
}
```

### 4. 本地缓存备份

```javascript
// 本地存储管理
class LocalLogCache {
    static save(logs) {
        const cached = JSON.parse(localStorage.getItem('pendingLogs') || '[]');
        cached.push(...logs);
        
        // 限制缓存大小，防止存储溢出
        if (cached.length > 5000) {
            cached.splice(0, cached.length - 5000);
        }
        
        localStorage.setItem('pendingLogs', JSON.stringify(cached));
    }
    
    static getAndClear() {
        const logs = JSON.parse(localStorage.getItem('pendingLogs') || '[]');
        localStorage.removeItem('pendingLogs');
        return logs;
    }
    
    static retrySubmit() {
        const cachedLogs = this.getAndClear();
        if (cachedLogs.length > 0) {
            return submitLogsInBatches(cachedLogs);
        }
    }
}
```

## 🎯 实际应用场景

### 1. 用户行为跟踪

```javascript
// 用户点击跟踪
document.addEventListener('click', function(event) {
    globalLogQueue.add({
        level: 'INFO',
        message: `用户点击: ${event.target.tagName}`,
        module: 'UserBehavior',
        userId: getCurrentUserId()
    });
});

// 页面路由变化
window.addEventListener('hashchange', function() {
    globalLogQueue.add({
        level: 'INFO',
        message: `路由变化: ${window.location.hash}`,
        module: 'Router',
        userId: getCurrentUserId()
    });
});
```

### 2. 错误监控

```javascript
// 全局错误捕获
window.addEventListener('error', function(event) {
    globalLogQueue.add({
        level: 'ERROR',
        message: event.message,
        module: 'GlobalError',
        stack: event.error ? event.error.stack : '',
        url: event.filename,
        metadata: JSON.stringify({
            line: event.lineno,
            column: event.colno
        })
    });
});

// Promise错误捕获
window.addEventListener('unhandledrejection', function(event) {
    globalLogQueue.add({
        level: 'ERROR',
        message: `Promise rejection: ${event.reason}`,
        module: 'PromiseError',
        stack: event.reason.stack || ''
    });
});
```

### 3. 性能监控

```javascript
// 页面加载性能
window.addEventListener('load', function() {
    const navigation = performance.getEntriesByType('navigation')[0];
    globalLogQueue.add({
        level: 'INFO',
        message: '页面加载完成',
        module: 'Performance',
        metadata: JSON.stringify({
            loadTime: navigation.loadEventEnd - navigation.fetchStart,
            domReady: navigation.domContentLoadedEventEnd - navigation.fetchStart
        })
    });
});
```

## ⚙️ 配置说明

### application.yml配置
```yaml
# 前端日志配置
frontend:
  log:
    enabled: true                      # 启用前端日志功能
    max-batch-size: 100               # 批量日志最大数量
    level-mapping:                     # 日志级别映射
      debug: DEBUG
      info: INFO
      warn: WARN
      error: ERROR

# 服务器配置
server:
  tomcat:
    max-http-post-size: 20MB          # 支持大量日志数据

# HTTP请求限制
spring:
  servlet:
    multipart:
      max-file-size: 20MB
      max-request-size: 20MB
```

### 环境声明配置
```yaml
# 环境声明（不激活Profile）
app:
  environment: dev  # 可选值：dev, test, prod
```

## 📊 监控和查询

### 查看日志文件信息
```bash
curl http://localhost:8080/api/frontend-log/info
```

### 获取最近日志内容
```bash
curl http://localhost:8080/api/frontend-log/recent?lines=100
```

### 查看系统配置
```bash
curl http://localhost:8080/api/frontend-log/config
```

## 🔧 测试页面

访问 http://localhost:8080/frontend-log-test.html 进行可视化测试：
- 单条日志记录表单
- 批量日志生成和提交
- 快速日志记录按钮
- 配置信息查看
- 日志文件信息显示

## ⚠️ 注意事项

1. **时间格式**: 必须使用 `yyyy-MM-dd HH:mm:ss` 格式，不支持ISO 8601格式
2. **字段验证**: 超出大小限制的请求会被拒绝并返回400错误
3. **异步处理**: 日志写入是异步的，返回成功不代表立即写入文件
4. **磁盘空间**: 需要监控日志目录的磁盘使用情况
5. **网络异常**: 建议实现本地缓存机制处理网络中断情况 